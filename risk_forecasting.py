# -*- coding: utf-8 -*-
"""Risk Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SfpKg8A_pLd7_zJiOO3_RTUN-X-xx42X
"""

# Import libraries
import yfinance as yf
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
import shap
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

# Define tickers and weights (equal-weight portfolio)
tickers = ['AAPL', 'MSFT', 'JPM', 'AMZN', 'SPY']
weights = np.array([0.2, 0.2, 0.2, 0.2, 0.2])  # Must match number of tickers

# Download Adjusted Close prices only
data = yf.download(tickers, start="2015-01-01", end="2025-01-01", auto_adjust=False)
adj_close = data['Adj Close'][tickers]  # Keep only our selected tickers

# Compute daily returns and portfolio returns
returns = adj_close.pct_change().dropna()
portfolio_returns = returns.dot(weights)  # Dot product: shape (n_days, 5) · (5,) → (n_days,)

# Historical VaR and Expected Shortfall (baseline)
VaR_95 = np.percentile(portfolio_returns, 5)
ES_95 = portfolio_returns[portfolio_returns < VaR_95].mean()
VaR_99 = np.percentile(portfolio_returns, 1)
ES_99 = portfolio_returns[portfolio_returns < VaR_99].mean()

print(f"Historical VaR (95%): {VaR_95:.4f}")
print(f"Historical ES  (95%): {ES_95:.4f}")
print(f"Historical VaR (99%): {VaR_99:.4f}")
print(f"Historical ES  (99%): {ES_99:.4f}")

# Feature engineering for ML model
df = pd.DataFrame(portfolio_returns, columns=['returns'])
df['volatility'] = df['returns'].rolling(20).std()
df['skewness'] = df['returns'].rolling(20).skew()
df['kurtosis'] = df['returns'].rolling(20).kurt()
df['lag_1'] = df['returns'].shift(1)
df['lag_2'] = df['returns'].shift(2)
df['lag_5'] = df['returns'].shift(5)
df.dropna(inplace=True)  # Drop rows with NaN (from rolling & shift)

# Split data into features and target
X = df.drop(columns=['returns'])
y = df['returns']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Train XGBoost model to predict 1-day ahead returns
model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# ML-based VaR and ES estimation
VaR_95_ml = np.percentile(y_pred, 5)
ES_95_ml = y_pred[y_pred < VaR_95_ml].mean()
VaR_99_ml = np.percentile(y_pred, 1)
ES_99_ml = y_pred[y_pred < VaR_99_ml].mean()

print(f"\nML-Based VaR (95%): {VaR_95_ml:.4f}")
print(f"ML-Based ES  (95%): {ES_95_ml:.4f}")
print(f"ML-Based VaR (99%): {VaR_99_ml:.4f}")
print(f"ML-Based ES  (99%): {ES_99_ml:.4f}")

# Backtesting: count how many actual returns fell below predicted VaR
exceptions_95 = sum(y_test < VaR_95_ml)
print(f"\nBacktesting Exceptions below VaR 95%: {exceptions_95} out of {len(y_test)} test samples")

# Scenario-Based Stress Testing (e.g., COVID-19 crash)
crisis_returns = returns.loc['2020-03-01':'2020-04-30'].dot(weights)
VaR_crisis_95 = np.percentile(crisis_returns, 5)
ES_crisis_95 = crisis_returns[crisis_returns < VaR_crisis_95].mean()

print(f"\nStress Test (COVID Crash - Mar-Apr 2020):")
print(f"VaR (95%): {VaR_crisis_95:.4f}")
print(f"ES  (95%): {ES_crisis_95:.4f}")

# SHAP Explainability
explainer = shap.Explainer(model)
shap_values = explainer(X_test)

# Save summary plot as image
shap.summary_plot(shap_values, X_test, show=False)
plt.tight_layout()
plt.savefig("shap_summary_plot.png")
print("\nSHAP summary plot saved as 'shap_summary_plot.png'")

